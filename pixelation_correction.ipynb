{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db93e929-e36c-46ac-8b8e-4f970d9c9160",
   "metadata": {},
   "source": [
    "# INSTALLING THE DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b8f10-07d6-4088-bc66-77e767d4c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187cd374-79b2-4b18-944c-cd5c137969e2",
   "metadata": {},
   "source": [
    "# IMPORT THE NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7077c-cd2a-4800-8972-a6bfda82dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ae8c1-0f87-4a3f-a8bf-761cee4ddc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths to original and pixelated images\n",
    "original_images_path = r\"C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\Image_Processing\\Original\"\n",
    "pixelated_images_path = r\"C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\Image_Processing\\Pixelated\"\n",
    "\n",
    "# Create train and test directories\n",
    "train_dir = r\"C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\train\"\n",
    "test_dir = r\"C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\test\"\n",
    "\n",
    "# Create subdirectories for original and pixelated images\n",
    "os.makedirs(os.path.join(train_dir, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, 'pixelated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'original'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, 'pixelated'), exist_ok=True)\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(source_dir, train_dir, test_dir, split_ratio=0.8):\n",
    "    files = os.listdir(source_dir)\n",
    "    random.shuffle(files)\n",
    "    split_point = int(len(files) * split_ratio)\n",
    "    train_files = files[:split_point]\n",
    "    test_files = files[split_point:]\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(train_dir, os.path.basename(source_dir)))\n",
    "    \n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(test_dir, os.path.basename(source_dir)))\n",
    "\n",
    "# Split the datasets\n",
    "split_dataset(original_images_path, train_dir, test_dir)\n",
    "split_dataset(pixelated_images_path, train_dir, test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99fc8c-33fe-4296-9f00-fbc2d7d4dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the directory containing RRDBNet_arch.py to sys.path\n",
    "sys.path.append(r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\ESRGAN')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee555db-eddb-4cc7-92bd-6ab6854067ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869df34-b41e-47ee-adda-23e333ff158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define a custom dataset class for ESRGAN\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "# Example transforms for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to desired input size\n",
    "    transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "])\n",
    "\n",
    "# Example dataset and DataLoader\n",
    "train_dataset = SuperResolutionDataset(data_dir=r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac7705-fdeb-4378-b7e5-2d327b75e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\pixelated_image_detector.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Compile the model (optional, but helps to avoid the warning)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fd6fe-3e92-4859-afdd-7bced837c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7325b51-b79c-452e-b261-ae7841cecec0",
   "metadata": {},
   "source": [
    "# DETECTING AND CORRECTING THE PIXELATED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87ec7b-f5f0-4645-932f-fed88c77fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Add the directory containing RRDBNet_arch.py to sys.path if not added already\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\ESRGAN')\n",
    "\n",
    "# Import your architecture file for ESRGAN\n",
    "import RRDBNet_arch as arch\n",
    "\n",
    "# Define image dimensions\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "# Load the pre-trained detection model\n",
    "detection_model_path = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\pixelated_image_detector.h5'\n",
    "detection_model = load_model(detection_model_path)\n",
    "\n",
    "# Compile the detection model\n",
    "detection_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the pre-trained ESRGAN model for super-resolution using PyTorch\n",
    "esrgan_model_path = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\ESRGAN\\models\\RRDB_ESRGAN_x4.pth'\n",
    "esrgan_model = arch.RRDBNet(3, 3, 64, 23, gc=32)\n",
    "esrgan_model.load_state_dict(torch.load(esrgan_model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "esrgan_model.eval()  # Set the model to evaluation mode\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "esrgan_model = esrgan_model.to(device)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\" Preprocess the image for pixelation detection. \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "class PixelatedImageApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Pixelated Image Detection and Correction\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        self.root.configure(bg='pink')\n",
    "        \n",
    "        self.load_image_button = tk.Button(self.root, text=\"Load Image\", command=self.load_image, bg='lightblue', width=20, height=2)\n",
    "        self.load_image_button.pack(pady=20)\n",
    "        \n",
    "        self.pixelation_status_label = tk.Label(self.root, text=\"Pixelation Status: \",bg='pink')\n",
    "        self.pixelation_status_label.pack(pady=10)\n",
    "        \n",
    "        self.detect_button = tk.Button(self.root, text=\"Detect Pixelation\", command=self.detect_pixelation, bg='lightblue', width=20, height=2)\n",
    "        self.detect_button.pack(pady=10)\n",
    "        \n",
    "        self.correct_button = tk.Button(self.root, text=\"Correct Image\", command=self.correct_image, bg='lightblue', width=20, height=2)\n",
    "        self.correct_button.pack(pady=10)\n",
    "        \n",
    "        self.original_image_label = tk.Label(self.root)\n",
    "        self.original_image_label.pack(pady=20, side=tk.LEFT)\n",
    "        \n",
    "        self.corrected_image_label = tk.Label(self.root)\n",
    "        self.corrected_image_label.pack(pady=20, side=tk.RIGHT)\n",
    "        \n",
    "        self.result_label = tk.Label(self.root, text=\"\")\n",
    "        self.result_label.pack(pady=10)\n",
    "        \n",
    "        self.image_path = None\n",
    "        self.original_image = None\n",
    "        self.corrected_image = None\n",
    "    \n",
    "    def load_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            self.image_path = file_path\n",
    "            self.original_image = Image.open(file_path)\n",
    "            self.display_image(self.original_image, self.original_image_label)\n",
    "            self.result_label.config(text=\"\")\n",
    "            self.pixelation_status_label.config(text=\"Pixelation Status: \")\n",
    "    \n",
    "    def display_image(self, image, label):\n",
    "        image = image.resize((400, 300))  # Resize for display if needed\n",
    "        img = ImageTk.PhotoImage(image)\n",
    "        label.config(image=img)\n",
    "        label.image = img  # Keep a reference to prevent garbage collection\n",
    "        \n",
    "    def detect_pixelation(self):\n",
    "        if self.image_path:\n",
    "            try:\n",
    "                processed_image = preprocess_image(self.image_path)\n",
    "                prediction = detection_model.predict(processed_image)\n",
    "                \n",
    "                if prediction > 0.5:\n",
    "                    self.pixelation_status_label.config(text=\"Pixelation Status: Pixelated\")\n",
    "                    self.result_label.config(text=\"Image is Pixelated!\")\n",
    "                else:\n",
    "                    self.pixelation_status_label.config(text=\"Pixelation Status: Not Pixelated\")\n",
    "                    self.result_label.config(text=\"Image is not Pixelated.\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error detecting pixelation: {str(e)}\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first.\")\n",
    "    \n",
    "    def correct_image(self):\n",
    "        if self.image_path:\n",
    "            try:\n",
    "                # Correct with ESRGAN\n",
    "                corrected_image_esrgan = self.correct_with_esrgan()\n",
    "                \n",
    "                # Display ESRGAN corrected image\n",
    "                esrgan_image = Image.fromarray(cv2.cvtColor(corrected_image_esrgan, cv2.COLOR_BGR2RGB))\n",
    "                self.display_image(esrgan_image, self.corrected_image_label)\n",
    "                self.result_label.config(text=\"Image is Corrected!\")\n",
    "                \n",
    "                # Save the corrected ESRGAN image (optional)\n",
    "                corrected_image_path_esrgan = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\corrected_image_esrgan.jpg'\n",
    "                cv2.imwrite(corrected_image_path_esrgan, corrected_image_esrgan)\n",
    "                print(f'ESRGAN Corrected image saved at {corrected_image_path_esrgan}')\n",
    "                \n",
    "                # Correct with Real-ESRGAN\n",
    "                corrected_image_real_esrgan = self.correct_with_real_esrgan()\n",
    "                \n",
    "                # Display Real-ESRGAN corrected image\n",
    "                real_esrgan_image = Image.fromarray(cv2.cvtColor(corrected_image_real_esrgan, cv2.COLOR_BGR2RGB))\n",
    "                self.display_image(real_esrgan_image, self.corrected_image_label)\n",
    "                self.result_label.config(text=\"Image is Corrected!\")\n",
    "                \n",
    "                # Save the corrected Real-ESRGAN image (optional)\n",
    "                corrected_image_path_real_esrgan = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\corrected_image_real_esrgan.jpg'\n",
    "                cv2.imwrite(corrected_image_path_real_esrgan, corrected_image_real_esrgan)\n",
    "                print(f'Real-ESRGAN Corrected image saved at {corrected_image_path_real_esrgan}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error correcting image: {str(e)}\")\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Please load an image first.\")\n",
    "    \n",
    "    def correct_with_esrgan(self):\n",
    "        img = cv2.imread(self.image_path, cv2.IMREAD_COLOR)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = torch.from_numpy(np.transpose(img, (2, 0, 1))).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Downscale the image if it's too large\n",
    "        if img.shape[2] > 512 or img.shape[3] > 512:\n",
    "            print(\"Downscaling the image to fit into memory.\")\n",
    "            img = torch.nn.functional.interpolate(img, size=(512, 512), mode='bicubic')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = esrgan_model(img).squeeze().cpu().clamp_(0, 1).numpy()\n",
    "        \n",
    "        corrected_image = np.transpose(output, (1, 2, 0))\n",
    "        corrected_image = (corrected_image * 255.0).round().astype(np.uint8)\n",
    "        print(\"Corrected using ESRGAN\")\n",
    "        return corrected_image\n",
    "    \n",
    "    def correct_with_real_esrgan(self):\n",
    "        real_esrgan_exe = r\"C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\Real_ESRGAN\\realesrgan-ncnn-vulkan.exe\"\n",
    "        command = [real_esrgan_exe, '-i', self.image_path, '-o', 'output_image.png']\n",
    "\n",
    "        try:\n",
    "            subprocess.run(command, shell=True, check=True)\n",
    "            \n",
    "            # Load and return the enhanced image\n",
    "            enhanced_image = cv2.imread('output_image.png', cv2.IMREAD_COLOR)\n",
    "            if enhanced_image is None:\n",
    "                raise ValueError(\"Error: Real-ESRGAN output image not found or unable to read.\")\n",
    "            \n",
    "            os.remove('output_image.png')  # Clean up temporary output file\n",
    "            \n",
    "            return enhanced_image\n",
    "        \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            raise RuntimeError(f\"Error running Real-ESRGAN: {e}\")\n",
    "\n",
    "# Function to start the Tkinter GUI\n",
    "def start_gui():\n",
    "    root = tk.Tk()\n",
    "    app = PixelatedImageApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "# Start the Tkinter GUI\n",
    "start_gui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c98eb-86d3-4be1-a849-0572028a63c3",
   "metadata": {},
   "source": [
    "# EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c85dce-011b-40bb-b134-720aabeff3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\" Preprocess the image for pixelation detection. \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Error: Unable to read image at {image_path}\")\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def evaluate_detection_model(test_images_dir):\n",
    "    \"\"\" Evaluate the detection model on a test dataset. \"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(test_images_dir):\n",
    "        print(f\"Test images directory does not exist: {test_images_dir}\")\n",
    "        return\n",
    "\n",
    "    # Ensure the directory is not empty\n",
    "    if not os.listdir(test_images_dir):\n",
    "        print(f\"Test images directory is empty: {test_images_dir}\")\n",
    "        return\n",
    "\n",
    "    for image_name in os.listdir(test_images_dir):\n",
    "        image_path = os.path.join(test_images_dir, image_name)\n",
    "        print(f\"Processing image: {image_path}\")  # Debugging statement\n",
    "\n",
    "        label = 1 if 'pixelated' in image_name else 0\n",
    "\n",
    "        try:\n",
    "            processed_image = preprocess_image(image_path)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        prediction = detection_model.predict(processed_image)\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(1 if prediction > 0.5 else 0)\n",
    "\n",
    "        # Debugging statement to show the processing status\n",
    "        print(f\"Processed {image_name}, True label: {label}, Prediction: {prediction}\")\n",
    "   \n",
    "\n",
    "# Example usage\n",
    "test_images_dir = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\test_images'\n",
    "evaluate_detection_model(test_images_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd30f8-a8b9-4bd9-baa9-e869a9ac60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load your dataset\n",
    "def load_images_from_folder(folder, img_width=128, img_height=128):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subfolder in ['pixelated', 'non_pixelated']:\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            raise ValueError(f\"Subfolder {subfolder_path} does not exist.\")\n",
    "        \n",
    "        label = 1 if subfolder == 'pixelated' else 0\n",
    "        \n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            img_path = os.path.join(subfolder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                # Resize image\n",
    "                img = cv2.resize(img, (img_width, img_height))\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    print(f\"Loaded {len(images)} images with labels: {set(labels)}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess_image(image, img_width=128, img_height=128):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    return image\n",
    "\n",
    "# Prepare dataset\n",
    "def prepare_dataset(folder, img_width=128, img_height=128):\n",
    "    images, labels = load_images_from_folder(folder, img_width, img_height)\n",
    "    if len(images) == 0:\n",
    "        raise ValueError(\"No images found in the folder.\")\n",
    "    if len(set(labels)) < 2:\n",
    "        raise ValueError(\"Dataset does not contain both classes.\")\n",
    "    processed_images = np.array([preprocess_image(img) for img in images])\n",
    "    return processed_images, labels\n",
    "\n",
    "# Load dataset\n",
    "folder_path = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\test'\n",
    "X, y = prepare_dataset(folder_path)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for classical machine learning models\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Load the pre-trained detection model\n",
    "detection_model_path = r'C:\\Users\\ilang\\OneDrive\\Desktop\\pix\\pixelated_image_detector.h5'\n",
    "detection_model = load_model(detection_model_path)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, f1\n",
    "\n",
    "# Define and evaluate models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC()\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    accuracy, f1 = evaluate_model(model, X_train_flat, y_train, X_test_flat, y_test)\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\\n\")\n",
    "\n",
    "# Optionally, you can also evaluate the pre-trained detection model\n",
    "def evaluate_keras_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.where(y_pred > 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    f1 = f1_score(y_test, y_pred_classes)\n",
    "    return accuracy, f1\n",
    "\n",
    "accuracy, f1 = evaluate_keras_model(detection_model, X_test, y_test)\n",
    "print(\"Pre-trained Keras Model:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdab88-601f-4827-b735-8f8d2c2127f6",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beebf50-49c6-4ed6-936c-adbd43756dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels, respectively\n",
    "# Replace these with your actual true and predicted labels\n",
    "y_true = np.array([1, 0, 0, 1, 1, 1, 0, 1, 0, 0])\n",
    "y_pred = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print confusion matrix (optional)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = np.unique(y_true)\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
